{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "PdCY_mbBBuQT"
   },
   "outputs": [],
   "source": [
    "from music21 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "автоматическая генерация музыки - это процесс создания небольшого музыкального произведения с минимальным вмешательством человека."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 1787 году Моцарт предложил <b>игру в кости</b> для случайного выбора звука (и он был не первым и не последним - https://ru.wikipedia.org/wiki/Музыкальная_игра_в_кости). \n",
    "<br>\n",
    "<br>\n",
    "В начале 1950-х Яннис Ксенакис использовал концепции статистики и вероятности для создания музыки, получившей название <b>стохастическая музыка</b> https://algorithmiccomposition.ru/article_entry_xenakis.html. Базовая идея: музыка - последовательность звуков, которая возникает случайно. Значит, выбор этих звуков может строго зависеть от математического аппарата.\n",
    "<br>\n",
    "<br>\n",
    "<b>Архитектуры глубокого обучения</b> стали \"легким\" решением в рамках задачи автоматической генерации музыки. Почему именно DL \"выстрелил\" в этой задаче? - ответ прост, потому что требуются универсальные функциональные аппроксиматоры, а это нейросетки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Составные элементы музыки</b>\n",
    "<br><br>\n",
    "Звук, производимый одной клавишей, называется <b>нотой</b>.<br>\n",
    "Звук, воспроизводимый двумя или более клавишами одновременно, называется <b>аккордом</b>. Как правило, большинство аккордов содержат как минимум 3 ключевых звука.<br>\n",
    "Повторяющийся базисный музыкальный интервал называется <b>октавой</b>. Каждая октава содержит 7 белых и 5 черных клавиш."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Подход 1: использование WaveNet</h1>\n",
    "    <br>\n",
    "<p>WaveNet - модель генерации необработанного звука, разработанная Google DeepMind - https://en.wikipedia.org/wiki/WaveNet. Основная цель WaveNet - генерировать новые выборки из исходного распределения данных. То есть перед нами генеративная модель, которая очень похожа на языковые модели.\n",
    "<p>WaveNet принимает на входе кусок необработанной звуковой волны (которая представлена в виде значений амплитуды = временной ряд). <img src='http://ar.flashmode.tn/wp-content/uploads/2018/06/Shazam-Was-That-Song-Nickelback-Or-Pitbull.gif'>\n",
    "    <br><br>\n",
    "<p>Выход WaveNet:<br>\n",
    "<img src='https://habrastorage.org/getpro/habr/post_images/2fe/b25/464/2feb25464260ad8a96c983bb85340fee.gif'>\n",
    "    <br>\n",
    "    На каждом шагу семплинга значение вычисляется из вероятностного распределения посчитанного сетью. Затем это значение возвращается на вход и делается новое предсказание для следующего шага.\n",
    "    <br>\n",
    "    То есть перед нами построение авторегрессионной модели, в которой каждый семпл зависит от всех предыдущих.\n",
    "    <br><br>\n",
    "    Еще мы видим, что перед нами сверточная нейронная сеть (https://neurohive.io/ru/osnovy-data-science/glubokaya-svertochnaja-nejronnaja-set/), где слои имеют разные факторы дилатации и позволяют ее рецептивному полю расти экспоненциально с глубиной и покрывать тысячи временных отрезков. \n",
    "    \n",
    "<h1>Подход 2: использование модели долгой краткосрочной памяти (LSTM)</h1>\n",
    "    <br>\n",
    "<p> LSTM представляет собой вариант рекуррентных нейронных сетей (RNN) - https://ru.wikipedia.org/wiki/Долгая_краткосрочная_память, способна фиксировать долгосрочные зависимости во входной последовательности.\n",
    "<p>При обучении условные вероятности во все моменты времени могут вычисляться\n",
    "параллельно, потому что все значения сигнала x заранее известны. Во время генерации предсказания последовательны: каждая предсказанная точка подаётся обратно на вход нейросети, чтобы предсказать следующую.\n",
    "    \n",
    "<br><br>\n",
    " Подготовка входных и выходных последовательностей аналогична WaveNet. На каждом временном шаге значение амплитуды загружается в ячейку памяти - затем модель вычисляет скрытый вектор и передает его на следующий шаг. Текущий скрытый вектор на временном шаге вычисляется на основе текущего входного и ранее скрытого вектора.\n",
    " \n",
    "<p>почитать подробнее про плюсы и минусы моделей: https://habr.com/ru/company/wunderfund/blog/331310/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "bOzly2sODGcR"
   },
   "outputs": [],
   "source": [
    "# функция для чтения MIDI\n",
    "# возвращает массив нот и аккордов, присутствующих в музыкальном файле\n",
    "\n",
    "def read_midi(file):\n",
    "    \n",
    "    print(\"Загружаем файл:\",file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    # парсинг файла\n",
    "    midi = converter.parse(file)\n",
    "  \n",
    "    # группировка по разным инструментам\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    #перебор инструментов\n",
    "    for part in s2.parts:\n",
    "    \n",
    "        notes_to_parse = part.recurse() \n",
    "      \n",
    "        #определение: нота или аккорд\n",
    "        for element in notes_to_parse:\n",
    "                \n",
    "            #нота\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "                \n",
    "            #аккорд\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Z4RYBEfDI3A",
    "outputId": "d476bc3e-b04a-4a0a-9f6c-83efd9f86db6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружаем файл: samples/midi_songs_d-123trainwithme.mid\n",
      "Загружаем файл: samples/midi_songs_d-captainjack.mid\n",
      "Загружаем файл: samples/schubert_sonata_157_2_(c)yogore.mid\n",
      "Загружаем файл: samples/schubert_sonata_157_3_(c)yogore.mid\n"
     ]
    }
   ],
   "source": [
    "#загружаем файлы\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path='samples/'\n",
    "\n",
    "#читаем все файлы\n",
    "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "\n",
    "#изучаем midi\n",
    "notes_array = np.array([read_midi(path+i) for i in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-BVSk53DLjG",
    "outputId": "e1e0c442-aaee-43a5-9144-b480da0a71da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n"
     ]
    }
   ],
   "source": [
    "#2D массив в 1D \n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "#Кол-во уникального\n",
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "GpKme0M-EZB6",
    "outputId": "abcf9864-bc29-4975-d514-3c8bc6e80b68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([115.,  22.,  10.,   3.,   6.,   1.,   0.,   1.,   1.,   2.]),\n",
       " array([  1. ,  77.4, 153.8, 230.2, 306.6, 383. , 459.4, 535.8, 612.2,\n",
       "        688.6, 765. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 304,
       "width": 328
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#частота каждой ноты\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "#рассматривать только частоты\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графика мы можем сделать вывод, что большинство нот имеют низкую частоту. Проигнорируем низкочастотные звуки. Например, поставим порог в 50. Тем не менее, параметр можно изменить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XoBiN2QLEz1u",
    "outputId": "e1d3c653-e537-4d55-a38d-b2616afd6fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count>=25]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QpzZvk9BE4QG",
    "outputId": "788dd806-ddd1-4528-e931-edafb75e9b7f"
   },
   "outputs": [],
   "source": [
    "# подготовим новые музыкальные файлы, которые содержат только эти ноты.\n",
    "\n",
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp=[]\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)            \n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "HemoOvLXE6U7"
   },
   "outputs": [],
   "source": [
    "# Подготовка входных и выходных последовательностей\n",
    "\n",
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "        \n",
    "        \n",
    "        input_ = note_[i:i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "khuwe_tbE9he"
   },
   "outputs": [],
   "source": [
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "goEdKV_tE_dw"
   },
   "outputs": [],
   "source": [
    "#входные последовательности\n",
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        # каждой записи присваиваем уникальное целое число\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "iKY0z4atFBy4"
   },
   "outputs": [],
   "source": [
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Kwr9c0avFDv-"
   },
   "outputs": [],
   "source": [
    "# 80% данных для обучения, 20% для оценки:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "u1XeNkZWFGB5"
   },
   "outputs": [],
   "source": [
    "# Построение модели\n",
    "def lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128,return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPAH7UETFIAl",
    "outputId": "f893e1df-b5fb-41bb-dc37-3eb097c32264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 32, 100)           8000      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 32, 64)            19264     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16, 128)           24704     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 8, 256)            98560     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 80)                20560     \n",
      "=================================================================\n",
      "Total params: 236,880\n",
      "Trainable params: 236,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "a9BPuNnCFKTw"
   },
   "outputs": [],
   "source": [
    "# лучшая модель во время обучения\n",
    "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjsoCfczFNjt",
    "outputId": "3e5ab847-e474-40d3-8d5d-ad9787ae64fe",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 3.4596\n",
      "Epoch 00001: val_loss improved from inf to 3.00817, saving model to best_model.h5\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 3.4596 - val_loss: 3.0082\n",
      "Epoch 2/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 2.6738\n",
      "Epoch 00002: val_loss improved from 3.00817 to 2.64150, saving model to best_model.h5\n",
      "74/74 [==============================] - 8s 107ms/step - loss: 2.6738 - val_loss: 2.6415\n",
      "Epoch 3/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 2.4429\n",
      "Epoch 00003: val_loss improved from 2.64150 to 2.46067, saving model to best_model.h5\n",
      "74/74 [==============================] - 8s 102ms/step - loss: 2.4429 - val_loss: 2.4607\n",
      "Epoch 4/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 2.2467\n",
      "Epoch 00004: val_loss improved from 2.46067 to 2.27187, saving model to best_model.h5\n",
      "74/74 [==============================] - 7s 97ms/step - loss: 2.2467 - val_loss: 2.2719\n",
      "Epoch 5/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 2.0760\n",
      "Epoch 00005: val_loss improved from 2.27187 to 2.12251, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 81ms/step - loss: 2.0752 - val_loss: 2.1225\n",
      "Epoch 6/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.9278\n",
      "Epoch 00006: val_loss improved from 2.12251 to 2.01251, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 85ms/step - loss: 1.9278 - val_loss: 2.0125\n",
      "Epoch 7/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.8055\n",
      "Epoch 00007: val_loss improved from 2.01251 to 1.84196, saving model to best_model.h5\n",
      "74/74 [==============================] - 7s 89ms/step - loss: 1.8055 - val_loss: 1.8420\n",
      "Epoch 8/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.6859\n",
      "Epoch 00008: val_loss improved from 1.84196 to 1.72284, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 77ms/step - loss: 1.6859 - val_loss: 1.7228\n",
      "Epoch 9/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 1.5695\n",
      "Epoch 00009: val_loss improved from 1.72284 to 1.62158, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 86ms/step - loss: 1.5704 - val_loss: 1.6216\n",
      "Epoch 10/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.4738\n",
      "Epoch 00010: val_loss improved from 1.62158 to 1.57300, saving model to best_model.h5\n",
      "74/74 [==============================] - 7s 92ms/step - loss: 1.4738 - val_loss: 1.5730\n",
      "Epoch 11/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.4049\n",
      "Epoch 00011: val_loss improved from 1.57300 to 1.45617, saving model to best_model.h5\n",
      "74/74 [==============================] - 7s 90ms/step - loss: 1.4049 - val_loss: 1.4562\n",
      "Epoch 12/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.3253\n",
      "Epoch 00012: val_loss improved from 1.45617 to 1.41358, saving model to best_model.h5\n",
      "74/74 [==============================] - 7s 88ms/step - loss: 1.3253 - val_loss: 1.4136\n",
      "Epoch 13/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.2830\n",
      "Epoch 00013: val_loss improved from 1.41358 to 1.37409, saving model to best_model.h5\n",
      "74/74 [==============================] - 7s 95ms/step - loss: 1.2830 - val_loss: 1.3741\n",
      "Epoch 14/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.2197\n",
      "Epoch 00014: val_loss improved from 1.37409 to 1.32051, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 87ms/step - loss: 1.2197 - val_loss: 1.3205\n",
      "Epoch 15/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.1765\n",
      "Epoch 00015: val_loss improved from 1.32051 to 1.28390, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 85ms/step - loss: 1.1765 - val_loss: 1.2839\n",
      "Epoch 16/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.1390\n",
      "Epoch 00016: val_loss improved from 1.28390 to 1.23472, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 83ms/step - loss: 1.1390 - val_loss: 1.2347\n",
      "Epoch 17/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 1.0805\n",
      "Epoch 00017: val_loss improved from 1.23472 to 1.21194, saving model to best_model.h5\n",
      "74/74 [==============================] - 7s 88ms/step - loss: 1.0806 - val_loss: 1.2119\n",
      "Epoch 18/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.0516- ETA: \n",
      "Epoch 00018: val_loss improved from 1.21194 to 1.17827, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 86ms/step - loss: 1.0516 - val_loss: 1.1783\n",
      "Epoch 19/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 1.0407\n",
      "Epoch 00019: val_loss improved from 1.17827 to 1.17380, saving model to best_model.h5\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 1.0407 - val_loss: 1.1738\n",
      "Epoch 20/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.9884\n",
      "Epoch 00020: val_loss improved from 1.17380 to 1.13229, saving model to best_model.h5\n",
      "74/74 [==============================] - 7s 93ms/step - loss: 0.9884 - val_loss: 1.1323\n",
      "Epoch 21/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.9620\n",
      "Epoch 00021: val_loss improved from 1.13229 to 1.12767, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 79ms/step - loss: 0.9612 - val_loss: 1.1277\n",
      "Epoch 22/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.9374\n",
      "Epoch 00022: val_loss improved from 1.12767 to 1.10227, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 80ms/step - loss: 0.9391 - val_loss: 1.1023\n",
      "Epoch 23/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.9094\n",
      "Epoch 00023: val_loss improved from 1.10227 to 1.08509, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 79ms/step - loss: 0.9101 - val_loss: 1.0851\n",
      "Epoch 24/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.8875\n",
      "Epoch 00024: val_loss improved from 1.08509 to 1.05668, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 78ms/step - loss: 0.8875 - val_loss: 1.0567\n",
      "Epoch 25/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.8456\n",
      "Epoch 00025: val_loss did not improve from 1.05668\n",
      "74/74 [==============================] - 5s 71ms/step - loss: 0.8460 - val_loss: 1.0567\n",
      "Epoch 26/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.8348\n",
      "Epoch 00026: val_loss improved from 1.05668 to 1.03173, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 77ms/step - loss: 0.8341 - val_loss: 1.0317\n",
      "Epoch 27/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7979\n",
      "Epoch 00027: val_loss did not improve from 1.03173\n",
      "74/74 [==============================] - 5s 70ms/step - loss: 0.7980 - val_loss: 1.0368\n",
      "Epoch 28/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.8051\n",
      "Epoch 00028: val_loss improved from 1.03173 to 1.01636, saving model to best_model.h5\n",
      "74/74 [==============================] - 5s 71ms/step - loss: 0.8051 - val_loss: 1.0164\n",
      "Epoch 29/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7781\n",
      "Epoch 00029: val_loss improved from 1.01636 to 1.00847, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 87ms/step - loss: 0.7781 - val_loss: 1.0085\n",
      "Epoch 30/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7405\n",
      "Epoch 00030: val_loss improved from 1.00847 to 0.99588, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 80ms/step - loss: 0.7399 - val_loss: 0.9959\n",
      "Epoch 31/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.7409\n",
      "Epoch 00031: val_loss improved from 0.99588 to 0.97989, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 77ms/step - loss: 0.7423 - val_loss: 0.9799\n",
      "Epoch 32/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7021\n",
      "Epoch 00032: val_loss improved from 0.97989 to 0.95508, saving model to best_model.h5\n",
      "74/74 [==============================] - 7s 91ms/step - loss: 0.7021 - val_loss: 0.9551\n",
      "Epoch 33/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.7032- E\n",
      "Epoch 00033: val_loss did not improve from 0.95508\n",
      "74/74 [==============================] - 7s 91ms/step - loss: 0.7032 - val_loss: 0.9564\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/74 [============================>.] - ETA: 0s - loss: 0.6832\n",
      "Epoch 00034: val_loss improved from 0.95508 to 0.94588, saving model to best_model.h5\n",
      "74/74 [==============================] - 7s 91ms/step - loss: 0.6825 - val_loss: 0.9459\n",
      "Epoch 35/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6640\n",
      "Epoch 00035: val_loss improved from 0.94588 to 0.94578, saving model to best_model.h5\n",
      "74/74 [==============================] - 7s 92ms/step - loss: 0.6637 - val_loss: 0.9458\n",
      "Epoch 36/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6608- ET\n",
      "Epoch 00036: val_loss improved from 0.94578 to 0.92307, saving model to best_model.h5\n",
      "74/74 [==============================] - 7s 95ms/step - loss: 0.6608 - val_loss: 0.9231\n",
      "Epoch 37/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6472\n",
      "Epoch 00037: val_loss did not improve from 0.92307\n",
      "74/74 [==============================] - 6s 82ms/step - loss: 0.6472 - val_loss: 0.9264\n",
      "Epoch 38/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6173\n",
      "Epoch 00038: val_loss improved from 0.92307 to 0.91367, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 88ms/step - loss: 0.6177 - val_loss: 0.9137\n",
      "Epoch 39/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.6155\n",
      "Epoch 00039: val_loss improved from 0.91367 to 0.89737, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 78ms/step - loss: 0.6164 - val_loss: 0.8974\n",
      "Epoch 40/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.6076\n",
      "Epoch 00040: val_loss did not improve from 0.89737\n",
      "74/74 [==============================] - 6s 76ms/step - loss: 0.6076 - val_loss: 0.9027\n",
      "Epoch 41/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5886\n",
      "Epoch 00041: val_loss improved from 0.89737 to 0.89604, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 79ms/step - loss: 0.5886 - val_loss: 0.8960\n",
      "Epoch 42/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5617\n",
      "Epoch 00042: val_loss did not improve from 0.89604\n",
      "74/74 [==============================] - 6s 75ms/step - loss: 0.5626 - val_loss: 0.8961\n",
      "Epoch 43/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5604\n",
      "Epoch 00043: val_loss improved from 0.89604 to 0.88592, saving model to best_model.h5\n",
      "74/74 [==============================] - 7s 96ms/step - loss: 0.5604 - val_loss: 0.8859\n",
      "Epoch 44/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5485\n",
      "Epoch 00044: val_loss did not improve from 0.88592\n",
      "74/74 [==============================] - 6s 79ms/step - loss: 0.5482 - val_loss: 0.8891\n",
      "Epoch 45/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5459\n",
      "Epoch 00045: val_loss did not improve from 0.88592\n",
      "74/74 [==============================] - 5s 73ms/step - loss: 0.5456 - val_loss: 0.8908\n",
      "Epoch 46/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5318\n",
      "Epoch 00046: val_loss did not improve from 0.88592\n",
      "74/74 [==============================] - 6s 75ms/step - loss: 0.5332 - val_loss: 0.8880\n",
      "Epoch 47/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.5252\n",
      "Epoch 00047: val_loss improved from 0.88592 to 0.87299, saving model to best_model.h5\n",
      "74/74 [==============================] - 7s 95ms/step - loss: 0.5252 - val_loss: 0.8730\n",
      "Epoch 48/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5034\n",
      "Epoch 00048: val_loss improved from 0.87299 to 0.87010, saving model to best_model.h5\n",
      "74/74 [==============================] - 7s 94ms/step - loss: 0.5025 - val_loss: 0.8701\n",
      "Epoch 49/50\n",
      "73/74 [============================>.] - ETA: 0s - loss: 0.5006\n",
      "Epoch 00049: val_loss improved from 0.87010 to 0.86594, saving model to best_model.h5\n",
      "74/74 [==============================] - 6s 78ms/step - loss: 0.4994 - val_loss: 0.8659\n",
      "Epoch 50/50\n",
      "74/74 [==============================] - ETA: 0s - loss: 0.4913\n",
      "Epoch 00050: val_loss did not improve from 0.86594\n",
      "74/74 [==============================] - 6s 87ms/step - loss: 0.4913 - val_loss: 0.8726\n"
     ]
    }
   ],
   "source": [
    "# Обучаем модель. размер батча 128, 50 эпох:\n",
    "\n",
    "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "xN9IeftyFPPo"
   },
   "outputs": [],
   "source": [
    "#загрузка лучшей модели\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TirNEZPXFSAz",
    "outputId": "5c8d3d10-8b18-411b-c4d4-7eda806e7b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62, 55, 1, 67, 65, 2, 1, 19, 31, 18, 1, 57, 28, 31, 18, 31, 28, 1, 57, 18, 3, 28, 1, 54, 28, 3, 18, 1, 54, 28, 58, 79, 1, 21, 55, 58, 79, 58, 55, 1, 21, 79, 62, 55, 1, 67, 65, 2, 1, 19]\n"
     ]
    }
   ],
   "source": [
    "# поехали сочинять: для прогнозов следуем шагам, указанным на этапе вывода.\n",
    "\n",
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "\n",
    "random_music = x_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(50):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "8gcMs0HeFUH8"
   },
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "95e5pjE8FWsq"
   },
   "outputs": [],
   "source": [
    "# обратное преобразование прогнозов в файл MIDI\n",
    "\n",
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # объекты нот и аккордов на основе значений, сгенерированных моделью\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # аккорд\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # нота\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # увеличиваем смещение на каждой итерации, чтобы ноты не слипались\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Vh1etmCiFZQ9"
   },
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6vCh7-MFbeu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled39.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
